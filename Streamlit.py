# streamlit_app.py
# import os
import numpy as np
import pandas as pd
import pickle
import matplotlib.pyplot as plt
import streamlit as st
# from OptunaOptimizedWeightedVotingRegressor import \
#     OptunaOptimizedWeightedVotingRegressor  # ç¡®ä¿è¿™ä¸ªæ–‡ä»¶å’Œä½ çš„appåœ¨åŒä¸€ç›®å½•ä¸‹ï¼Œæˆ–è€…åœ¨Pythonè·¯å¾„ä¸­
# --- é¡µé¢é…ç½® ---
# åœ¨è„šæœ¬çš„æœ€å¼€å§‹è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="CEGS Bias bearing capacity prediction system",
    page_icon="ğŸ—ï¸",  # å¯ä»¥è®¾ç½®ä¸€ä¸ªå›¾æ ‡
    layout="wide",  # ä½¿ç”¨å®½å¸ƒå±€
    initial_sidebar_state="expanded"  # ä¾§è¾¹æ é»˜è®¤å±•å¼€
)
# --- å…¨å±€è®¾ç½® ---
# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œç¡®ä¿Matplotlibå›¾è¡¨èƒ½æ­£ç¡®æ˜¾ç¤ºä¸­æ–‡
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
# --- å…¨å±€å˜é‡å’Œå‡½æ•° ---
model = None
scaler = None
feature_order = ['r', 'L', 'Î»', 'e', 'Î¸', 'D', 't', 'fc', 'fy', 'Î±', 'F', 'SF', 'SÎ±']
# åŠ è½½æ¨¡å‹çš„å‡½æ•°
@st.cache_resource  # ä½¿ç”¨Streamlitçš„ç¼“å­˜è£…é¥°å™¨ï¼Œè®©æ¨¡å‹åªåœ¨åº”ç”¨å¯åŠ¨æ—¶åŠ è½½ä¸€æ¬¡
def load_model():
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’Œç‰¹å¾ç¼©æ”¾å™¨"""
    try:
        with open("CEGS_optuna_ensemble_model.pkl", "rb") as f:
            saved_data = pickle.load(f)
        model = saved_data["ensemble_model"]
        scaler = saved_data["feature_scaler"]
        st.success("The model has been loaded successfullyï¼")
        return model, scaler
    except FileNotFoundError:
        st.error("The model file CEGS_optuna_ensemble_model.pkl was not found. Please ensure that the model file is in "
                 "the same directory as the application.")
        return None, None
    except Exception as e:
        st.error(f"An error occurred while loading the modelï¼š{str(e)}")
        return None, None
# éªŒè¯è¾“å…¥çš„å‡½æ•°
def validate_inputs(inputs):
    """éªŒè¯è¾“å…¥æ˜¯å¦æœ‰æ•ˆ"""
    try:
        validated = {}
        for key, value in inputs.items():
            if value is None:  # Streamlitçš„number_inputä¸ºç©ºæ—¶è¿”å›None
                raise ValueError(f"{key} Parameters cannot be empty")
            validated[key] = float(value)
        # æ£€æŸ¥å‚æ•°èŒƒå›´
        if not (0 <= validated['r'] <= 1): raise ValueError("r should be between 0 and 1")
        if not (100 <= validated['L'] <= 10000): raise ValueError("The L (mm) should be between 100 and 10,000")
        if not (0 <= validated['Î»'] <= 70): raise ValueError("Î» should be between 0 and 70")
        if not (0 <= validated['e'] <= 200): raise ValueError("e (mm) should be between 0 and 200")
        if not (0 <= validated['Î¸'] <= 5): raise ValueError("Î¸ should be between 0 and 5")
        if not (50 <= validated['D'] <= 300): raise ValueError("The D/B (mm) ratio should be between 50 and 300")
        if not (0 <= validated['t'] <= 10): raise ValueError("t (mm) should be between 0 and 10")
        if not (0 <= validated['fc'] <= 80): raise ValueError("The fc (MPa) should be between 0 and 80")
        if not (0 <= validated['fy'] <= 1200): raise ValueError("The fy (MPa) should be between 0 and 1200")
        if not (0 <= validated['Î±'] <= 0.5): raise ValueError("Î± should be between 0 and 0.5")
        if not (1 <= validated['F'] <= 2): raise ValueError("F should be between 1 and 2")
        if not (0 <= validated['SF'] <= 2): raise ValueError("SF should be between 0 and 2")
        if not (0 <= validated['SÎ±'] <= 0.5): raise ValueError("SÎ± should be between 0 and 0.5")

        return validated
    except ValueError as e:
        st.warning(str(e))
        return None
# --- åº”ç”¨ä¸»é€»è¾‘ ---
def main():
    global model, scaler
    # åˆå§‹åŒ–session_stateä¸­çš„æ¸…ç©ºæ ‡å¿—
    if 'clear_inputs' not in st.session_state:
        st.session_state.clear_inputs = False
    # è®¾ç½®ä¸»æ ‡é¢˜
    st.title("ğŸ—ï¸ CEGS Bias bearing capacity prediction system")
    # åŠ è½½æ¨¡å‹
    model, scaler = load_model()
    # åˆ›å»ºä¸€ä¸ªé€‰æ‹©æ¡†ï¼Œè®©ç”¨æˆ·é€‰æ‹©é¢„æµ‹æ¨¡å¼
    tab1, tab2 = st.tabs(["Single-sample prediction", "Batch prediction"])
    # --- å•æ ·æœ¬é¢„æµ‹æ ‡ç­¾é¡µ ---
    with tab1:
        st.header("Single-sample prediction")
        st.markdown("Please enter the following parameters for predictionï¼š")
        # åˆ›å»ºä¸€ä¸ªä¸¤åˆ—çš„å¸ƒå±€ï¼Œè®©è¾“å…¥æ¡†æ›´ç´§å‡‘
        col1, col2 = st.columns(2)
        # å®šä¹‰å‚æ•°ä¿¡æ¯ï¼Œæ–¹ä¾¿å¾ªç¯åˆ›å»º
        params_info = [
            ('r', 'The replacement rate of recycled concrete [r] ', 0.5, 0.0, 1.0),
            ('L', 'Column height [L(mm)]', 1000.0, 100.0, 10000.0),
            ('Î»', 'Slenderness ratio [Î»]', 10.0, 0.0, 70.0),
            ('e', 'Offset [e(mm)]', 50.0, 0.0, 200.0),
            ('Î¸', 'Confining factor [Î¸]', 1.0, 0.0, 5.0),
            ('D', 'Side length/Diameter [D/B(mm)]', 150.0, 50.0, 300.0),
            ('t', 'Thickness of steel pipe [t(mm)]', 5.0, 0.0, 10.0),
            ('fc', 'Compressive strength of core concrete [fc(MPa)]', 40.0, 0.0, 80.0),
            ('fy', 'Yield strength of steel pipes [fy(MPa)]', 400.0, 0.0, 1200.0),
            ('Î±', 'Steel ratio [Î±]', 0.02, 0.0, 0.5),
            ('F', 'Column section form [F]', 1.0, 1.0, 2.0),
            ('SF', 'Steel section form [SF]', 1.0, 0.0, 2.0),
            ('SÎ±', 'Steel content of section steel [SÎ±]', 0.01, 0.0, 0.5),
        ]

        user_inputs = {}
        # å¾ªç¯åˆ›å»ºè¾“å…¥æ¡†
        for i, (key, label, default_value, min_val, max_val) in enumerate(params_info):
            # æ ¹æ®session_stateå†³å®šè¾“å…¥æ¡†çš„åˆå§‹å€¼
            # å¦‚æœéœ€è¦æ¸…ç©ºï¼Œåˆ™valueä¸ºNoneï¼Œå¦åˆ™ä¸ºé»˜è®¤å€¼
            input_value = None if st.session_state.clear_inputs else default_value

            if i % 2 == 0:
                with col1:
                    user_inputs[key] = st.number_input(
                        label,
                        value=input_value,  # å…³é”®æ”¹åŠ¨ï¼šä½¿ç”¨åŠ¨æ€å€¼
                        min_value=min_val,
                        max_value=max_val,
                        step=0.01 if key in ['r', 'Î±', 'SÎ±', 'Î¸'] else 1.0,
                        format="%.4f" if key in ['r', 'Î±', 'SÎ±'] else "%.1f"
                    )
            else:
                with col2:
                    user_inputs[key] = st.number_input(
                        label,
                        value=input_value,  # å…³é”®æ”¹åŠ¨ï¼šä½¿ç”¨åŠ¨æ€å€¼
                        min_value=min_val,
                        max_value=max_val,
                        step=0.01 if key in ['r', 'Î±', 'SÎ±', 'Î¸'] else 1.0,
                        format="%.4f" if key in ['r', 'Î±', 'SÎ±'] else "%.1f"
                    )
        # æŒ‰é’®å¸ƒå±€
        button_col1, button_col2, button_col3 = st.columns([1, 1, 8])# è°ƒæ•´å®½åº¦æ¯”ä¾‹ï¼Œè®©æŒ‰é’®é åœ¨ä¸€èµ·
        with button_col1:
            predict_button = st.button("Start the prediction", type="primary")
        with button_col2:
            # å…³é”®æ”¹åŠ¨ï¼šæ·»åŠ æ¸…ç©ºæŒ‰é’®
            clear_button = st.button("Clear Inputs")
        # å¤„ç†æ¸…ç©ºæŒ‰é’®ç‚¹å‡»äº‹ä»¶
        if clear_button:
            st.session_state.clear_inputs = True
            # å¼ºåˆ¶é¡µé¢é‡æ–°è¿è¡Œï¼Œä»¥ç«‹å³æ˜¾ç¤ºæ¸…ç©ºæ•ˆæœ
            st.rerun()
        # å¤„ç†é¢„æµ‹æŒ‰é’®ç‚¹å‡»äº‹ä»¶
        if predict_button:
            # é¢„æµ‹å‰ï¼Œå…ˆé‡ç½®æ¸…ç©ºæ ‡å¿—ï¼Œè¿™æ ·ä¸‹æ¬¡è¾“å…¥æ¡†ä¼šæ˜¾ç¤ºé»˜è®¤å€¼
            st.session_state.clear_inputs = False

            if not model or not scaler:
                st.warning("The model has not been loaded and thus cannot make predictions.")
                return
            # éªŒè¯è¾“å…¥
            validated_inputs = validate_inputs(user_inputs)
            if not validated_inputs:
                return
            # å‡†å¤‡ç‰¹å¾
            features = np.array([validated_inputs[feat] for feat in feature_order]).reshape(1, -1)
            scaled_features = scaler.transform(features)

            try:
                # è¿›è¡Œé¢„æµ‹
                Nu = model.predict(scaled_features)[0]
                individual_preds = model.predict_individual(scaled_features)
                # æ˜¾ç¤ºç»“æœ
                st.subheader("Outcome")
                result_container = st.container(border=True)  # åˆ›å»ºä¸€ä¸ªå¸¦è¾¹æ¡†çš„å®¹å™¨ç¾åŒ–æ˜¾ç¤º
                with result_container:
                    st.write(f"**Integrated model prediction of Nu (Bias bearing Capacity):** {Nu:.2f} kN")

                    st.write("**The prediction results of each sub-model:**")
                    for model_name, pred_value in individual_preds.items():
                        st.write(f"  - {model_name}: {pred_value[0]:.2f} kN")

                    st.write("**Model weight:**")
                    for model_name, weight in model.weights.items():
                        st.write(f"  - {model_name}: {weight:.4f} ({weight * 100:.1f}%)")

            except Exception as e:
                st.error(f"Error in predictionï¼š{str(e)}")
    # --- æ‰¹é‡é¢„æµ‹æ ‡ç­¾é¡µ ---
    with tab2:
        st.header("Batch prediction")
        st.markdown("Please upload an Excel file containing the required parameters for batch prediction.")
        # æ–‡ä»¶ä¸Šä¼ æ§ä»¶
        uploaded_file = st.file_uploader("Select the Excel file", type=["xlsx", "xls"])

        if uploaded_file is not None:
            try:
                df = pd.read_excel(uploaded_file)
                st.success(f"The file has been uploaded successfully! A total of {len(df)} data points were detected.")
                # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
                st.subheader("Data preview")
                st.dataframe(df.head())
                # æ£€æŸ¥åˆ—æ˜¯å¦é½å…¨
                missing_cols = [col for col in feature_order if col not in df.columns]
                if missing_cols:
                    st.warning(f"The uploaded file is missing the necessary columnsï¼š{', '.join(missing_cols)}")
                else:
                    # é¢„æµ‹æŒ‰é’®
                    if st.button("Start batch prediction", type="primary"):
                        if not model or not scaler:
                            st.warning("The model has not been loaded and thus cannot make predictions.")
                            return

                        with st.spinner("Batch prediction is underway. Please wait a moment..."):
                            # å‡†å¤‡ç‰¹å¾
                            features = df[feature_order].values
                            scaled_features = scaler.transform(features)
                            # è¿›è¡Œé¢„æµ‹
                            batch_Nu = model.predict(scaled_features)
                            # åˆ›å»ºç»“æœDataFrame
                            result_df = df.copy()
                            # ä¿®æ­£ï¼šä¿®å¤åˆ—åçš„è¯­æ³•é”™è¯¯
                            result_df['Integrated model prediction Nu (kN)'] = batch_Nu
                            # å¦‚æœåŸå§‹æ•°æ®åŒ…å«çœŸå®å€¼Nuï¼Œè®¡ç®—è¯¯å·®
                            if 'Nu' in df.columns:
                                result_df['Absolute error (kN)'] = np.abs(df['Nu'] - batch_Nu)
                                result_df['Relative error (%)'] = np.abs((df['Nu'] - batch_Nu) / df['Nu']) * 100
                                # è®¡ç®—å¹¶æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                                avg_abs_error = np.mean(result_df['Absolute error (kN)'])
                                avg_rel_error = np.mean(result_df['Relative error (%)'])

                                st.subheader("Statistics of prediction results")
                                stats_container = st.container(border=True)
                                with stats_container:
                                    st.write(f"**Mean absolute error (MAE):** {avg_abs_error:.2f} kN")
                                    st.write(f"**Average relative error:** {avg_rel_error:.2f}%")
                        # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
                        st.subheader("Batch prediction results")
                        st.dataframe(result_df)
                        # æä¾›ä¸‹è½½é“¾æ¥
                        csv = result_df.to_csv(index=False)
                        st.download_button(
                            label="Download the prediction results (CSV)",
                            data=csv,
                            file_name="Batch prediction results.csv",
                            mime="text/csv",
                        )

            except Exception as e:
                st.error(f"An error occurred while processing the fileï¼š{str(e)}")
# --- è¿è¡Œåº”ç”¨ ---
if __name__ == "__main__":
    main()